数值最优化方法：
* 梯度下降法
  * Batch_gradient_descent
  * Stochastic_gradient_descent
  * mini_Batch_gradient_descent
 
* 牛顿法
* 坐标下降法
----
为什么要采用迭代法
对于含有$e^x$,log(x),sin(x),arctan(x)的为超越方程，不容易直接找到导数或者梯度为0的点。

既然一步不能到位，那就一步一步到位
故采用迭代法

----
## 梯度下降法
迭代公式：$$X_{k+1}=X_{k}-\eta \nabla f(X)$$  
注意事项：  
使用前需要进行数值归一化  
实现细节问题：
* 初始值的设定
* 步长的选择
* 迭代终止的判定规则

----
## 牛顿法
迭代公式: $$X_{k+1} = X_{k} - H^{-1}g\gamma$$
注意事项：
* 有可能H无逆矩阵或者H的拟计算过于复杂
* 不一定能收敛到极小值点
* $\gamma$的选择可以用到直线搜索

----
## 坐标下降法
每次循环优化一个变量，将问题转化为一元函数求极值，达到函数的极小值点。  
对于一个变量的优化问题，可以采用牛顿法也可以直接用公式解。

优势：  
对于某些复杂的问题计算较为简便

劣势：  
若目标函数不光滑，则坐标下降法有可能陷入非驻点

----
待学习
牛顿法由于在计算海森矩阵的逆矩阵时，计算量较大，故有拟牛顿法，各种拟牛顿法可以之后再细细学习
