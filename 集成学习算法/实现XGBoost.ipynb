{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目录\n",
    "* XGBoost算法推导\n",
    "* XGBoost算法实现\n",
    "* 使用自制的数据集进行测试\n",
    "* 使用波士顿数据集进行测试，并与sklearn中的Adaboost,RandomForest进行对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost算法推导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost是梯度提升树中的改进算法，所以具有梯度提升树中的一些共性，同时也存在自己的个性  \n",
    "对于梯度提升树算法来说，有三个关键部分需要明确  \n",
    "1. 能够让弱评估器集成的手段（迭代方法、抽样手段、样本加权）\n",
    "2. 能够衡量集成算法效果的损失函数  \n",
    "3. 弱评估器$f_k(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.集成手段  \n",
    "$$\\hat y_i^{(k)} = \\hat y_i^{(k-1)} + \\eta f_{k}(X_i)$$\n",
    "其中$\\eta$为shrinkage或者理解为learning rate  \n",
    "一般设置为 eta=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.能够衡量集成算法效果的损失函数\n",
    "$$Obj^{(k)} = \\sum\\limits_{i=1}^m l(y_i,\\hat y^{(k)}) + \\sum\\limits_{k=1}^K \\Omega(f_k)$$\n",
    "\n",
    "其中加号的左侧部分为传统的损失函数，衡量模型是否拟合训练数据  \n",
    "常见的损失函数  \n",
    "reg:linear --> 平方误差 $l(y_i,\\hat y_i) = (y_i - \\hat y_i)^2$  \n",
    "binary:logistic --> $l(y_i,\\hat y_i) = y_i ln(1+e^{-\\hat y_i})+(1-y_i)ln(1+e^{\\hat y_i})$  \n",
    "binary:hinge  \n",
    "multi:softmax\n",
    "\n",
    "\n",
    "可以将算法理解为，左侧在减小算法的偏差（模型的准确度），右侧在减小算法的方法（模型在不同数据集上的稳定性）\n",
    "\n",
    "接下来的Obj的过程中，将目标函数转化为与树结构直接相关的写法，以此建立树结构与模型效果之间的直接联系。所以目标函数又称为“结构分数”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Obj^{(k)} = \\sum\\limits_{i=1}^ml(y_i,\\hat y_i^{(k-1)}+f_k(x_i))+\\Omega(f_k)+constant$$\n",
    "根据泰勒展开式\n",
    "$$f(x+\\Delta x) \\approx f(x)+f'(x)\\Delta x + \\frac{1}{2}f''(x)\\Delta x^2$$\n",
    "故原式按泰勒展开\n",
    "$$Obj^{(k)} = \\sum \\limits_{i=1}^m \\big[ l(y_i,\\hat y_i^{(k-1)}) + gif_k(x_i) + \\frac{1}{2}h_i f_k^2(x_i) \\big]  +\\Omega(f_k)+constant$$\n",
    "其中\n",
    "$$g_i=\\frac{\\partial l(y_i,\\hat y ^{(k-1)})}{\\partial \\hat y^{(k-1)}}$$\n",
    "$$h_i = \\frac{\\partial^2 l(y_i,\\hat y ^{(k-1)})}{\\partial {\\hat y^{(k-1)}}^2}$$\n",
    "$g_i$,$h_i$可以理解为是每个样本的梯度统计量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于$\\Omega{(f_k)}$，即树的复杂度，可以采用叶子结点的数量来进行衡量。同时加上L1和L2正则项\n",
    "故\n",
    "$$\\Omega{(f_k)} = \\gamma T + \\frac{1}{2}\\alpha\\sum\\limits_{j=1}^T|w_j|+\\frac{1}{2}\\lambda\\sum\\limits_{j=1}^Tw_j^2$$\n",
    "通常采用L2正则，\n",
    "故$\\alpha=0$,$\\lambda=1$  \n",
    "设定$\\gamma=0$  \n",
    "其中T为叶子节点的个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将样本映射到对应的叶子节点上，也就是\n",
    "$$f_k(x) = w_{q(x)}$$\n",
    "故Obj公式可以进一步推导  \n",
    "$$Obj^{(k)} = \\sum \\limits_{i=1}^m \\big[ w_{q(x_i)}g_i + \\frac{1}{2}w_{q(x_i)}^2h_i \\big] + \\gamma T + \\frac{1}{2}\\lambda \\sum\\limits_{j=1}^Tw_j^2 + constant$$\n",
    "定义索引为j的叶子上含有的样本集合为$I_j$  \n",
    "故上式继续推导为\n",
    "$$Obj^{(k)} = \\sum \\limits_{j=1}^T \\big( w_j \\sum\\limits_{i \\in I_j }g_i  \\big) + \\frac{1}{2} \\big( w_j^2 \\sum\\limits_{i \\in I_j}h_i  \\big) + \\gamma T +\\frac{1}{2}\\lambda \\sum\\limits_{i=1}^T w_j^2$$\n",
    "\n",
    "合并一些项，化简为  \n",
    "$$Obj^{(k)} = \\sum\\limits_{i=1}^T \\big[ w_jG_j+\\frac{1}{2}w_j^2(H_j+\\lambda) \\big]+\\gamma T$$\n",
    "其中\n",
    "$$G_j = \\sum\\limits_{i \\in I_j}g_i$$\n",
    "$$H_j = \\sum\\limits_{i \\in I_j}h_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求每个叶子的$w_j^*$  \n",
    "$Obj^{(k)}$对$w_j$求导，得  \n",
    "$$G_j +w_j (H_j+\\lambda)=0$$\n",
    "故\n",
    "$$w_j^* = -\\frac{G_j}{H_j+\\lambda}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将$w_j^*$带入$Obj^{(k)}$得  \n",
    "$$Obj^{(k)} =  - \\frac{1}{2}\\sum\\limits_{j=1}^T \\frac{G_j^2}{H_j+\\lambda}+\\gamma T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "故当我们确定了树结构后，每个叶子节点的权重$w_j^*$就可以确定  \n",
    "下一个问题，如果确定树结构  \n",
    "采用的方式为贪婪算法：寻找最佳分枝  \n",
    "这个最佳是如何衡量的呢？  \n",
    "计算分枝前与分枝后的结构分数之差Gain，选择Gain最大的特征上的分枝点进行分枝。若最大的Gain为负，则停止生长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Gain = Score_{middle} - (Score_{left}+Score_{right})$$\n",
    "$$=\\frac{1}{2}\\big[ \\frac{G_L^2}{H_L+\\lambda} + \\frac{G_R^2}{H_R+\\lambda} - \\frac{(G_L+G_R)^2}{H_L+ H_R +\\lambda} \\big]-\\gamma$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何找到最佳分枝呢？  \n",
    "对所有的特征的所有分枝进行Gain计算  \n",
    "选出让目标函数下降最快的节点来分枝  \n",
    "我们规定，只要结构函数之差Gain>0，即目标函数能够继续减小，我们就允许树继续分枝  \n",
    "即\n",
    "$$\\frac{1}{2}\\big[ \\frac{G_L^2}{H_L+\\lambda} + \\frac{G_R^2}{H_R+\\lambda} - \\frac{(G_L+G_R)^2}{H_L+ H_R +\\lambda} \\big]>\\gamma$$\n",
    "故可以通过设定$\\gamma$，让XGBoost中的树停止生长。  \n",
    "所以$\\gamma$可以定义为在树的节点上进一步分枝所需的减小量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结算法的流程：\n",
    "1. 初始化$f_0(x)=0,\\hat y^{(0)}=0$  \n",
    "    a. 根据$\\hat y^{(k-1)}$更新$g_i$和$h_i$  \n",
    "    b. 根据贪婪算法，寻找最佳分枝，进行建树  \n",
    "    c. 根据所建的树，计算每个叶子节点的$w_j$  \n",
    "    d. 更新$f_k(x)$,$\\hat y^{(k)} = \\hat y^{(k-1)}+\\eta f_k(x)$\n",
    "2. 直到建立num_round棵树，停止迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost算法实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现XGBoost回归器，其中采用平方误差为损失函数，故将上述的算法过程进一步具体化\n",
    "1. 初始化$f_0(x)=0,\\hat y^{(0)}=0$  \n",
    "    a. 根据$\\hat y^{(k-1)}$更新$g_i$和$h_i$  \n",
    "$$g_i = -2(y_i - \\hat y^{(k-1)})$$\n",
    "$$h_i = 2$$\n",
    "    b. 根据贪婪算法，寻找最佳分枝，进行建树  \n",
    "            其中\n",
    "$$Gain = \\frac{1}{2}\\big[ \\frac{G_L^2}{H_L+\\lambda} + \\frac{G_R^2}{H_R+\\lambda} - \\frac{(G_L+G_R)^2}{H_L+ H_R +\\lambda} \\big]-\\gamma$$\n",
    "    c. 根据所建的树，计算每个叶子节点的$w_j$  \n",
    "$$w_j^*=-\\frac{G_j}{H_j+\\lambda}$$\n",
    "    d. 更新$f_k(x)$,$\\hat y^{(k)} = \\hat y^{(k-1)}+\\eta f_k(x)$\n",
    "2. 直到建立num_round棵树，停止迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$g_i = -2*(y_i - \\hat y^{(k-1)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Try_XGBoost():\n",
    "    def __init__(self,num_round=10,eta=0.3,gamma=0,Lambda=1,scoring=\"mse\"):\n",
    "        self.scoring = scoring\n",
    "        self.num_round = num_round\n",
    "        self.eta = eta\n",
    "        self.gamma = gamma\n",
    "        self.Lambda = Lambda\n",
    "        self.ensemble = []\n",
    "        self.g = None\n",
    "        self.h = None\n",
    "        self.haty = None \n",
    "        self.f = None \n",
    "        \n",
    "    def _G(self,y_train):\n",
    "        \"\"\"计算g_i\"\"\"\n",
    "        return -2*(y_train - self.haty)\n",
    "\n",
    "    def _Gain(self,listL,listR):\n",
    "        \"\"\"计算Gain，方便确定最佳分枝\"\"\"\n",
    "        GL = self.g[listL].sum()\n",
    "        GR = self.g[listR].sum()\n",
    "        HL = self.h[listL].sum()\n",
    "        HR = self.h[listR].sum()\n",
    "        \n",
    "        return (GL**2/(HL+self.Lambda)+GR**2/(HR+self.Lambda)-(GR+GL)**2/(HL+HR+self.Lambda))/2-self.gamma\n",
    "    \n",
    "    def _w(self,indexlist):\n",
    "        return -np.sum(self.g[indexlist])/(np.sum(self.h[indexlist])+self.Lambda)\n",
    "    def fit(self,X_train,y_train):\n",
    "        \n",
    "        def BestSplit(X_train,y_train,indexlist):\n",
    "            \"\"\"寻找最佳切分，如果有最佳切分，返回切分特征和切分值;如果无最佳切分，返回None\"\"\"\n",
    "            bestGain = 0\n",
    "            bestSplitFeature = -1\n",
    "            bestSplitValue = -1\n",
    "            for Feature in range(X_train.shape[1]):\n",
    "                ValueSet = set(X_train[:,Feature])\n",
    "                for Val in ValueSet:\n",
    "                    boolindexLeft = X_train[:,Feature] <= Val\n",
    "                    boolindexRight = ~boolindexLeft\n",
    "                    indexLeft = indexlist[boolindexLeft]\n",
    "                    indexRight = indexlist[boolindexRight]\n",
    "                    gain = self._Gain(indexLeft,indexRight)\n",
    "                    if gain > bestGain:\n",
    "                        bestGain = gain\n",
    "                        bestSplitFeature = Feature\n",
    "                        bestSplitValue = Val\n",
    "            if bestSplitFeature == -1:\n",
    "                return None,None\n",
    "            else:\n",
    "                return bestSplitFeature,bestSplitValue\n",
    "        \n",
    "        \n",
    "        def create_tree(X_train,y_train,indexlist = np.arange(len(X_train))):\n",
    "            \"\"\"建立新树，以字典形式保存，并更新self.f(这次更新后每个样本的目标分数)\"\"\"\n",
    "            \n",
    "            bestSplitFeature,bestSplitValue = BestSplit(X_train,y_train,indexlist)\n",
    "            if bestSplitFeature is None:\n",
    "                w = self._w(indexlist)\n",
    "                self.f[indexlist] = w\n",
    "                return w\n",
    "            else :\n",
    "                left_index = X_train[:,bestSplitFeature] <= bestSplitValue\n",
    "                sub_X_train_left,sub_y_train_left = X_train [left_index],y_train[left_index]\n",
    "                sub_X_train_right,sub_y_train_right = X_train [~left_index] ,y_train[~left_index]\n",
    "                indexlist_left = indexlist[left_index]\n",
    "                indexlist_right = indexlist[~left_index]\n",
    "                leftchild = create_tree(sub_X_train_left,sub_y_train_left,indexlist_left)\n",
    "                rightchild = create_tree(sub_X_train_right,sub_y_train_right,indexlist_right)\n",
    "                return {bestSplitFeature:{\"<={}\".format(bestSplitValue): leftchild,\">{}\".format(bestSplitValue): rightchild}}\n",
    "        \n",
    "        \n",
    "        self.haty = np.zeros(len(X_train))\n",
    "        self.h = np.ones(len(X_train))*2\n",
    "\n",
    "        for _ in range(self.num_round):\n",
    "            self.g = self._G(y_train)\n",
    "            self.f = np.empty(len(X_train))\n",
    "            newtree = create_tree(X_train,y_train)\n",
    "            self.ensemble.append(newtree)\n",
    "            self.haty = self.haty + self.eta*self.f\n",
    "        return\n",
    "    \n",
    "\n",
    "        \n",
    "    def draw_one_tree(self,index):\n",
    "        from graphviz import Digraph\n",
    "\n",
    "        def export_graphviz(tree,root_index): \n",
    "            root = next(iter(tree))\n",
    "            text_node.append([str(root_index),\"feature:{}\".format(root)])\n",
    "            secondDic = tree[root]\n",
    "            for key in secondDic:\n",
    "                if type(secondDic[key]) == dict:\n",
    "                    i[0] += 1\n",
    "                    secondrootindex=i[0]\n",
    "                    text_edge.append([str(root_index),str(secondrootindex),str(key)])\n",
    "                    export_graphviz(secondDic[key],secondrootindex)\n",
    "                else:\n",
    "                    i[0] += 1\n",
    "                    text_node.append([str(i[0]),str(secondDic[key])])\n",
    "                    text_edge.append([ str(root_index) , str(i[0]) , str(key) ])\n",
    "\n",
    "\n",
    "        tree = self.ensemble[index]\n",
    "        text_node=[]\n",
    "        text_edge=[]\n",
    "        i=[1]\n",
    "        export_graphviz(tree,i[0])\n",
    "        dot = Digraph()\n",
    "        for line in text_node:\n",
    "            dot.node(line[0],line[1])\n",
    "        for line in text_edge:\n",
    "            dot.edge(line[0],line[1],line[2])\n",
    "\n",
    "        dot.view()\n",
    "        \n",
    "        \n",
    "    def predict(self,X_test):\n",
    "        return np.array([self._predict(test) for test in X_test])\n",
    "        \n",
    "    def _predict(self,test):\n",
    "        \"\"\"对单条测试集进行预测\"\"\"\n",
    "        def __predict(tree,test):\n",
    "            feature = next(iter(tree))\n",
    "            secondDic = tree[feature]\n",
    "            content = test[feature]\n",
    "            for key in secondDic:\n",
    "                if eval(str(content)+key):\n",
    "                    if type(secondDic[key]) == dict :\n",
    "                        return __predict(secondDic[key],test)\n",
    "                    else:\n",
    "                        return secondDic[key]\n",
    "\n",
    "        assert len(self.ensemble) != 0,\"fit before predict\"\n",
    "        res = 0\n",
    "        for i in range(len(self.ensemble)):\n",
    "            tree = self.ensemble[i]\n",
    "            res_temp = __predict(tree,test)\n",
    "            res += res_temp*self.eta\n",
    "        return res\n",
    "    \n",
    "    def score(self,X_test,y_test):\n",
    "        y_pre = self.predict(X_test)\n",
    "        if self.scoring == \"mse\":\n",
    "            return sum((y_test-y_pre)**2)/len(X_test)\n",
    "        elif self.scoring==\"r2\":\n",
    "            return 1 - sum((y_test-y_pre)**2)/sum((y_test-y_test.mean())**2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_params(self,deep=False):\n",
    "        dic={}\n",
    "        dic[\"num_round\"]=self.num_round\n",
    "        dic[\"eta\"] = self.eta\n",
    "        dic[\"gamma\"] = self.gamma\n",
    "        dic[\"Lambda\"] = self.Lambda\n",
    "        dic[\"scoring\"] = self.scoring\n",
    "        return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用自制的数据集进行功能测试\n",
    "### 数据说明\n",
    "仿照陈天奇的ppt中的例子构建的数据集，第一列特征为年龄，第二列特征为是否为男性  \n",
    "预测值为 对电脑游戏的喜欢程度  \n",
    "一共为5个样本，1 boy,2 mother,3 grandpa,4 girl,5 grandma  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [13,1],\n",
    "    [30,0],\n",
    "    [63,1],\n",
    "    [12,0],\n",
    "    [63,0]\n",
    "])\n",
    "y = np.array([5,2,1,4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>is male</th>\n",
       "      <th>the degree of favor in computer games</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  is male  the degree of favor in computer games\n",
       "0   13        1                                      5\n",
       "1   30        0                                      2\n",
       "2   63        1                                      1\n",
       "3   12        0                                      4\n",
       "4   63        0                                      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.concat([pd.DataFrame(X,columns=[\"age\",\"is male\"]),pd.DataFrame(y,columns=[\"the degree of favor in computer games\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Try_XGBoost()\n",
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0: {'<=13': 3.6, '>13': 1.4285714285714286}},\n",
       " {0: {'<=13': 2.7359999999999998,\n",
       "   '>13': {1: {'<=0': 1.2571428571428571, '>0': 0.38095238095238093}}}},\n",
       " {0: {'<=13': 2.0793600000000003,\n",
       "   '>13': {1: {'<=0': 0.9554285714285715, '>0': 0.3047619047619048}}}},\n",
       " {0: {'<=13': 1.5803136000000002,\n",
       "   '>13': {1: {'<=0': 0.7261257142857144, '>0': 0.24380952380952384}}}},\n",
       " {0: {'<=13': 1.2010383360000003,\n",
       "   '>13': {1: {'<=0': 0.5518555428571428, '>0': 0.19504761904761905}}}},\n",
       " {0: {'<=13': 0.9127891353600003,\n",
       "   '>13': {1: {'<=0': 0.41941021257142863, '>0': 0.15603809523809523}}}},\n",
       " {0: {'<=13': {0: {'<=12': 0.24476645239466688, '>12': 0.9114331190613335}},\n",
       "   '>13': {1: {'<=0': 0.31875176155428575, '>0': 0.12483047619047616}}}},\n",
       " {0: {'<=13': {0: {'<=12': 0.1958131619157335, '>12': 0.7291464952490667}},\n",
       "   '>13': 0.21583569096620409}},\n",
       " {0: {'<=13': {0: {'<=12': 0.15665052953258693, '>12': 0.5833171961992534}},\n",
       "   '>13': {1: {'<=0': 0.1904507729493682, '>0': 0.05669724275914012}}}},\n",
       " {0: {'<=13': {0: {'<=12': 0.12532042362606965, '>12': 0.4666537569594027}},\n",
       "   '>13': {1: {'<=0': 0.14474258744151988, '>0': 0.045357794207312084}}}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画出其中一棵树看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.draw_one_tree(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07539524128331372"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X,y)#均方误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9650947957021696"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = Try_XGBoost(scoring=\"r2\")\n",
    "reg.fit(X,y)\n",
    "reg.score(X,y)#r2值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比sklearn中的随机森林回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stacy/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9037037037037037"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg_sklearn_rf = RandomForestRegressor(n_estimators=5)\n",
    "reg_sklearn_rf.fit(X,y)\n",
    "reg_sklearn_rf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "reg_sklearn_ad = AdaBoostRegressor(n_estimators=5,learning_rate=0.3)\n",
    "reg_sklearn_ad.fit(X,y)\n",
    "reg_sklearn_ad.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用波士顿数据集进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=2,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB=Try_XGBoost(scoring='r2',num_round=50,eta=0.1,gamma=0.2)\n",
    "XGB.fit(X_train,y_train)\n",
    "XGB_score = XGB.score(X_test,y_test) \n",
    "\n",
    "sklearn_Ada = AdaBoostRegressor(n_estimators=50,random_state=22)\n",
    "sklearn_Ada.fit(X_train,y_train)\n",
    "Ada_score = sklearn_Ada.score(X_train,y_train)\n",
    "\n",
    "sklearn_RF = RandomForestRegressor(n_estimators=50,random_state=22)\n",
    "sklearn_RF.fit(X_train,y_train)\n",
    "RF_score = sklearn_RF.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "score = [XGB_score,Ada_score,RF_score]\n",
    "plt.barh(range(3),score,color=[\"orange\",\"gold\",\"yellowgreen\"])\n",
    "plt.yticks(range(3),[\"Try_XGBoost_score\",\"AdaBoostRegressor_score\",\"RandomForest_score\"])\n",
    "plt.xlim([0.8,1])\n",
    "for loc1,loc2 in enumerate(score):\n",
    "    plt.text(loc2,loc1,\"{:.3f}\".format(loc2),va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB.draw_one_tree(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林真的是，一骑绝尘的优秀  \n",
    "我自己写的XGBoost除了慢以外，计算准确度还是可以和其他集成算法比拼一下的。    \n",
    "XGBoost的优点是性能快呀，有机会再看看论文，学习下如何加快算法的计算速度。  \n",
    "可能我调的参数不太理想，还是很过拟合。\n",
    "比如这棵树，就甚是枝繁叶茂。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
